# ğŸ› BUG REPORT - Chatbot Entity Extraction Not Working

**Date:** December 9, 2025, 10:34 AM  
**Reporter:** Backend Team  
**Severity:** ğŸ”´ HIGH (Core feature broken)  
**Status:** ACTIVE  
**Assigned to:** Chatbot/Rasa Team

---

## ğŸ“‹ SUMMARY

Chatbot action Ä‘ang gá»­i **TOÃ€N Bá»˜ user input** lÃ m search query thay vÃ¬ extract `product_name` entity. Äiá»u nÃ y lÃ m backend API khÃ´ng tÃ¬m Ä‘Æ°á»£c sáº£n pháº©m.

---

## ğŸ”´ ISSUE

### **Test Case:**

**User input:**
```
"tÃ´i cáº§n tÃ¬m ao-khoac-nam-lightweight-windbreaker-form-regular"
```

**What chatbot sends to API:**
```python
query = "tÃ´i cáº§n tÃ¬m ao-khoac-nam-lightweight-windbreaker-form-regular"
# âŒ WRONG - sending entire sentence
```

**What should be sent:**
```python
query = "ao-khoac-nam-lightweight-windbreaker-form-regular"
# âœ… CORRECT - only the product name/slug
```

---

## ğŸ“Š EVIDENCE

### **Chatbot Logs:**
```
2025-12-09 10:32:37 INFO  actions.api_client  
- Searching products with query: tÃ´i cáº§n tÃ¬m ao-khoac-nam-lightweight-windbreaker-form-regular, category: None

2025-12-09 10:32:37 INFO  actions.actions  
- âœ… API search_products took 0.604s

2025-12-09 10:32:37 INFO  actions.actions  
- âœ… Got 0 products from API 

2025-12-09 10:32:37 INFO  actions.actions  
- âš ï¸ No products found, returning empty message
```

### **Problem:**
1. Query includes: `"tÃ´i cáº§n tÃ¬m"` (unnecessary prefix)
2. Backend searches: `ILIKE %tÃ´i cáº§n tÃ¬m ao-khoac-nam-lightweight...%`
3. Product slug is: `"ao-khoac-nam-lightweight-windbreaker-form-regular"`
4. No match found â†’ 0 results

---

## ğŸ’¥ ROOT CAUSE

### **Suspected Code Issue:**

**File:** `actions/actions.py` (or similar)

```python
# âŒ WRONG CODE (suspected):
class ActionSearchProducts(Action):
    def run(self, dispatcher, tracker, domain):
        # Getting entire user message instead of entity
        query = tracker.latest_message.get('text')  # âŒ WRONG
        
        # OR not extracting entity properly
        product_name = tracker.get_slot("product_name")
        if not product_name:
            query = tracker.latest_message.get('text')  # âŒ FALLBACK TO FULL TEXT
        
        # Calling API with wrong query
        results = api_client.search_products(query)
```

**Should be:**

```python
# âœ… CORRECT CODE:
class ActionSearchProducts(Action):
    def run(self, dispatcher, tracker, domain):
        # Extract product_name entity first
        product_name = next(tracker.get_latest_entity_values("product_name"), None)
        
        # If no entity, try slot
        if not product_name:
            product_name = tracker.get_slot("product_name")
        
        # If still no entity, try to extract from text
        if not product_name:
            text = tracker.latest_message.get('text', '')
            product_name = self._extract_product_from_text(text)
        
        if not product_name:
            dispatcher.utter_message(
                text="Báº¡n muá»‘n tÃ¬m sáº£n pháº©m gÃ¬? VÃ­ dá»¥: Ã¡o khoÃ¡c, quáº§n jean..."
            )
            return []
        
        # Log what we're searching
        logger.info(f"ğŸ” Searching with extracted query: {product_name}")
        
        # Call API with EXTRACTED query only
        results = api_client.search_products(product_name)

    def _extract_product_from_text(self, text: str) -> str:
        """
        Extract product name from user text by removing common phrases
        """
        # Remove common prefixes
        prefixes = [
            'tÃ´i cáº§n tÃ¬m', 'tÃ´i muá»‘n tÃ¬m', 'tÃ¬m cho tÃ´i', 
            'cho tÃ´i xem', 'tÃ¬m giÃºp tÃ´i', 'tÃ¬m',
            'i want to find', 'find me', 'search for'
        ]
        
        cleaned = text.lower().strip()
        for prefix in prefixes:
            if cleaned.startswith(prefix):
                cleaned = cleaned[len(prefix):].strip()
                break
        
        return cleaned
```

---

## ğŸ› ï¸ HOW TO FIX

### **Priority 1: Fix Entity Extraction** (CRITICAL)

**Step 1: Check NLU Entity Annotation**

**File:** `data/nlu.yml`

Verify entities are properly annotated:

```yaml
- intent: search_product
  examples: |
    - tÃ´i cáº§n tÃ¬m [Ã¡o khoÃ¡c](product_name)
    - tÃ¬m cho tÃ´i [Ã¡o thun Ä‘en](product_name)
    - cÃ³ [Ã¡o polo](product_name) khÃ´ng
    - [Ã¡o khoÃ¡c nam](product_name)
    - tÃ´i cáº§n tÃ¬m [ao-khoac-nam-lightweight-windbreaker-form-regular](product_name)
```

**Step 2: Check Entity Extraction in Action**

**File:** `actions/actions.py`

```python
def run(self, dispatcher, tracker, domain):
    # Method 1: Get from entity (BEST)
    product_name = next(tracker.get_latest_entity_values("product_name"), None)
    logger.info(f"ğŸ“ Entity extracted: {product_name}")
    
    # Method 2: Get from slot (FALLBACK)
    if not product_name:
        product_name = tracker.get_slot("product_name")
        logger.info(f"ğŸ“ Slot value: {product_name}")
    
    # Method 3: Extract from text (LAST RESORT)
    if not product_name:
        text = tracker.latest_message.get('text', '')
        product_name = self._extract_product_from_text(text)
        logger.info(f"ğŸ“ Extracted from text: {product_name}")
    
    # Log what we're actually searching
    logger.info(f"ğŸ” Final search query: '{product_name}'")
    
    # Call API
    results = api_client.search_products(product_name)
```

**Step 3: Add Text Cleanup Helper**

```python
def _extract_product_from_text(self, text: str) -> str:
    """
    Remove common search phrases to extract actual product query
    """
    import re
    
    # Remove Vietnamese search phrases
    patterns = [
        r'^(tÃ´i\s+cáº§n\s+tÃ¬m)\s+',
        r'^(tÃ´i\s+muá»‘n\s+tÃ¬m)\s+',
        r'^(tÃ¬m\s+cho\s+tÃ´i)\s+',
        r'^(cho\s+tÃ´i\s+xem)\s+',
        r'^(tÃ¬m\s+giÃºp\s+tÃ´i)\s+',
        r'^(tÃ¬m)\s+',
        # English patterns
        r'^(i\s+want\s+to\s+find)\s+',
        r'^(find\s+me)\s+',
        r'^(search\s+for)\s+',
        r'^(show\s+me)\s+',
    ]
    
    cleaned = text.lower().strip()
    for pattern in patterns:
        cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)
    
    return cleaned.strip()
```

---

## ğŸ§ª TESTING

### **Test Case 1: Natural Language**
```
Input: "tÃ´i cáº§n tÃ¬m Ã¡o khoÃ¡c"

Expected Extraction:
- Full text: "tÃ´i cáº§n tÃ¬m Ã¡o khoÃ¡c"
- Entity/Extracted: "Ã¡o khoÃ¡c" âœ…
- API Query: "Ã¡o khoÃ¡c" âœ…
- Log: "ğŸ” Final search query: 'Ã¡o khoÃ¡c'"
```

### **Test Case 2: Slug Pattern**
```
Input: "tÃ´i cáº§n tÃ¬m ao-khoac-nam-lightweight-windbreaker-form-regular"

Expected Extraction:
- Full text: "tÃ´i cáº§n tÃ¬m ao-khoac-nam-lightweight-windbreaker-form-regular"
- Entity/Extracted: "ao-khoac-nam-lightweight-windbreaker-form-regular" âœ…
- API Query: "ao-khoac-nam-lightweight-windbreaker-form-regular" âœ…
- Log: "ğŸ” Final search query: 'ao-khoac-nam-lightweight-windbreaker-form-regular'"
```

### **Test Case 3: Direct Product Name**
```
Input: "Ã¡o polo"

Expected Extraction:
- Full text: "Ã¡o polo"
- Entity/Extracted: "Ã¡o polo" âœ…
- API Query: "Ã¡o polo" âœ…
```

### **Test Case 4: English**
```
Input: "i want to find a shirt"

Expected Extraction:
- Full text: "i want to find a shirt"
- Entity/Extracted: "shirt" âœ…
- API Query: "shirt" âœ…
```

---

## ğŸ“Š LOGS TO ADD

Add these logs Ä‘á»ƒ debug entity extraction:

```python
def run(self, dispatcher, tracker, domain):
    # Debug current state
    logger.info("=" * 50)
    logger.info("ğŸ” ACTION: action_search_products")
    
    # Log user input
    user_text = tracker.latest_message.get('text', '')
    logger.info(f"ğŸ‘¤ User input: '{user_text}'")
    
    # Log intent
    intent = tracker.latest_message.get('intent', {})
    logger.info(f"ğŸ¯ Intent: {intent.get('name')} (confidence: {intent.get('confidence')})")
    
    # Log entities
    entities = tracker.latest_message.get('entities', [])
    logger.info(f"ğŸ“Œ Entities detected: {entities}")
    
    # Try extraction methods
    entity_value = next(tracker.get_latest_entity_values("product_name"), None)
    logger.info(f"ğŸ“ Entity 'product_name': {entity_value}")
    
    slot_value = tracker.get_slot("product_name")
    logger.info(f"ğŸ° Slot 'product_name': {slot_value}")
    
    # Final query
    final_query = entity_value or slot_value or self._extract_product_from_text(user_text)
    logger.info(f"ğŸ” Final search query: '{final_query}'")
    logger.info(f"âœ… Query length: {len(final_query)} characters")
    logger.info("=" * 50)
    
    # Continue with search...
```

**Expected logs:**
```
==================================================
ğŸ” ACTION: action_search_products
ğŸ‘¤ User input: 'tÃ´i cáº§n tÃ¬m ao-khoac-nam-lightweight-windbreaker-form-regular'
ğŸ¯ Intent: search_product (confidence: 0.85)
ğŸ“Œ Entities detected: [{'entity': 'product_name', 'value': 'ao-khoac-nam-lightweight-windbreaker-form-regular', ...}]
ğŸ“ Entity 'product_name': ao-khoac-nam-lightweight-windbreaker-form-regular
ğŸ° Slot 'product_name': ao-khoac-nam-lightweight-windbreaker-form-regular
ğŸ” Final search query: 'ao-khoac-nam-lightweight-windbreaker-form-regular'
âœ… Query length: 51 characters
==================================================
```

---

## âœ… BACKEND STATUS

**Backend Ä‘Ã£ Ä‘Æ°á»£c improve** Ä‘á»ƒ handle cáº£ 2 cases:

### **Temporary Workaround Added:**

Backend API giá» tá»± Ä‘á»™ng extract slug pattern tá»« query:

```typescript
// Smart extraction in backend
const slugPattern = /([a-z0-9]+(?:-[a-z0-9]+){2,})/gi;
const slugMatches = search.match(slugPattern);

if (slugMatches) {
  // Search with BOTH full text AND extracted slug
  WHERE (name ILIKE '%full query%' OR slug ILIKE '%extracted-slug%')
}
```

**Example:**
```
Input: "tÃ´i cáº§n tÃ¬m ao-khoac-nam-lightweight..."
       â†“
Backend extracts: "ao-khoac-nam-lightweight..."
       â†“
Searches BOTH patterns
       â†“
âœ… Product found
```

**BUT:** This is a **workaround**. Chatbot should still fix entity extraction for:
1. Better performance (no need to search twice)
2. More accurate results
3. Cleaner logs
4. Standard architecture

---

## ğŸ“ ACTION ITEMS

### **Chatbot Team (URGENT):**

**Step 1: Add Detailed Logs (15 min)**
- [ ] Add logs cho entity extraction
- [ ] Log full text, entities, slots
- [ ] Log final query being sent to API
- [ ] Test vÃ  collect logs

**Step 2: Verify NLU (15 min)**
- [ ] Check `nlu.yml` entity annotations
- [ ] Verify entities are detected in `rasa shell nlu`
- [ ] Test with: "tÃ´i cáº§n tÃ¬m Ã¡o khoÃ¡c"
- [ ] Confirm entity value extracted correctly

**Step 3: Fix Action Code (30 min)**
- [ ] Implement proper entity extraction
- [ ] Add fallback to slot
- [ ] Add text cleanup as last resort
- [ ] Log each extraction attempt

**Step 4: Test (15 min)**
- [ ] Test natural language: "tÃ¬m Ã¡o khoÃ¡c"
- [ ] Test slug: "ao-khoac-nam-lightweight..."
- [ ] Test direct: "Ã¡o polo"
- [ ] Verify API receives clean query

**Total time:** ~1.5 hours

---

### **Backend Team:**
- [x] âœ… Added smart slug extraction (WORKAROUND DEPLOYED)
- [x] âœ… API now handles both full text and extracted slugs

---

## ğŸ¯ SUCCESS CRITERIA

After fix:
- âœ… Logs show: `"ğŸ” Final search query: 'ao-khoac-nam-lightweight...'"` (not full sentence)
- âœ… API receives clean query without "tÃ´i cáº§n tÃ¬m"
- âœ… Products found successfully
- âœ… Works for both natural language and slug inputs

---

## ğŸ’¡ QUICK DEBUG

**To verify current behavior, add this test:**

```python
# In rasa shell
User: tÃ´i cáº§n tÃ¬m Ã¡o khoÃ¡c

# Check logs - should see:
Entity extracted: "Ã¡o khoÃ¡c"  âœ…
Final query: "Ã¡o khoÃ¡c"  âœ…

# NOT this:
Entity extracted: None  âŒ
Final query: "tÃ´i cáº§n tÃ¬m Ã¡o khoÃ¡c"  âŒ
```

---

**Priority:** ğŸ”´ **HIGH - URGENT**  
**Impact:** Product search returns 0 results incorrectly  
**Timeline:** Fix today  
**Workaround:** Backend smart extraction (deployed)

---

**Bug Report Created:** 2025-12-09 10:34  
**Reporter:** Backend Team  
**Status:** Backend workaround deployed, chatbot fix needed
